{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6dbc5fe5",
   "metadata": {},
   "source": [
    "# Generate Test Dataset\n",
    "\n",
    "This notebook creates a smaller, more coherent testing set from `ai_human_ds.csv`:\n",
    "- 60 Human samples (label = 0)\n",
    "- 60 AI samples (label = 1)\n",
    "- Total: 120 samples\n",
    "\n",
    "The selected data will be saved as `gtest_data.csv`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614e1111",
   "metadata": {},
   "source": [
    "## Step 1: Import Libraries and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58a9f9b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 1460\n",
      "\n",
      "Column names: ['text', 'generated']\n",
      "\n",
      "Label distribution (generated column):\n",
      "  0 = Human, 1 = AI\n",
      "generated\n",
      "0    1375\n",
      "1      85\n",
      "Name: count, dtype: int64\n",
      "\n",
      "First few rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>generated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Machine learning, a subset of artificial intel...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A decision tree, a prominent machine learning ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Education, a cornerstone of societal progress,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Computers, the backbone of modern technology, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chess, a timeless game of strategy and intelle...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  generated\n",
       "0  Machine learning, a subset of artificial intel...          1\n",
       "1  A decision tree, a prominent machine learning ...          1\n",
       "2  Education, a cornerstone of societal progress,...          1\n",
       "3  Computers, the backbone of modern technology, ...          1\n",
       "4  Chess, a timeless game of strategy and intelle...          1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('ai_human_ds.csv')\n",
    "\n",
    "# Display basic information\n",
    "print(f\"Total samples: {len(df)}\")\n",
    "print(f\"\\nColumn names: {list(df.columns)}\")\n",
    "print(f\"\\nLabel distribution (generated column):\")\n",
    "print(f\"  0 = Human, 1 = AI\")\n",
    "print(df['generated'].value_counts())\n",
    "print(f\"\\nFirst few rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3839598",
   "metadata": {},
   "source": [
    "## Step 2: Sample 60 from Each Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "298e6276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available Human samples (generated=0): 1375\n",
      "Available AI samples (generated=1): 85\n",
      "\n",
      "‚úÖ Using 60 samples from each class as requested\n",
      "\n",
      "‚úÖ Selected 120 samples:\n",
      "   - Human (label=0): 60\n",
      "   - AI (label=1): 60\n",
      "\n",
      "DataFrame shape: (120, 2)\n",
      "Columns: ['text', 'label']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>We, the people of the United States, live in a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Last year in 2014, the earth had the warmest t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dear state senator, The Electoral College that...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Congestion, the amount of car traffic in a spe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The United States has been known for life, lib...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  We, the people of the United States, live in a...      0\n",
       "1  Last year in 2014, the earth had the warmest t...      0\n",
       "2  Dear state senator, The Electoral College that...      0\n",
       "3  Congestion, the amount of car traffic in a spe...      0\n",
       "4  The United States has been known for life, lib...      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separate data by label (generated column: 0 = Human, 1 = AI)\n",
    "human_samples = df[df['generated'] == 0]\n",
    "ai_samples = df[df['generated'] == 1]\n",
    "\n",
    "print(f\"Available Human samples (generated=0): {len(human_samples)}\")\n",
    "print(f\"Available AI samples (generated=1): {len(ai_samples)}\")\n",
    "\n",
    "# Since we only have 85 AI samples, we'll adjust our strategy\n",
    "# Option 1: Use all 85 AI samples and match with 85 human samples for balance\n",
    "# Option 2: Use 60 AI samples (if available) and 60 human samples as requested\n",
    "\n",
    "if len(ai_samples) >= 60:\n",
    "    # Use the requested 60 samples from each\n",
    "    n_samples = 60\n",
    "    human_selected = human_samples.sample(n=n_samples, random_state=42)\n",
    "    ai_selected = ai_samples.sample(n=n_samples, random_state=42)\n",
    "    print(f\"\\n‚úÖ Using {n_samples} samples from each class as requested\")\n",
    "else:\n",
    "    # Use all available AI samples and match with same number of human samples\n",
    "    n_samples = len(ai_samples)\n",
    "    human_selected = human_samples.sample(n=n_samples, random_state=42)\n",
    "    ai_selected = ai_samples\n",
    "    print(f\"\\n‚ö†Ô∏è  Only {n_samples} AI samples available. Using all AI samples and {n_samples} human samples for balance.\")\n",
    "\n",
    "# Combine the selected samples\n",
    "gtest_df = pd.concat([human_selected, ai_selected], ignore_index=True)\n",
    "\n",
    "# Shuffle the combined dataset\n",
    "gtest_df = gtest_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Rename 'generated' column to 'label' for clarity\n",
    "gtest_df = gtest_df.rename(columns={'generated': 'label'})\n",
    "\n",
    "print(f\"\\n‚úÖ Selected {len(gtest_df)} samples:\")\n",
    "print(f\"   - Human (label=0): {len(gtest_df[gtest_df['label'] == 0])}\")\n",
    "print(f\"   - AI (label=1): {len(gtest_df[gtest_df['label'] == 1])}\")\n",
    "print(f\"\\nDataFrame shape: {gtest_df.shape}\")\n",
    "print(f\"Columns: {list(gtest_df.columns)}\")\n",
    "gtest_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf499ce6",
   "metadata": {},
   "source": [
    "## Step 3: Inspect the Selected Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c379bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label distribution in test set:\n",
      "label\n",
      "0    60\n",
      "1    60\n",
      "Name: count, dtype: int64\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Example Human texts (label=0):\n",
      "================================================================================\n",
      "\n",
      "Sample 1:\n",
      "We, the people of the United States, live in a car happy society. Every teenager can't wait until their 16th birthday because, for mostly every kid, that means that they go get their drivers license and possibly their very own car. Also, adults always look at getting a nice luxurious car and the top...\n",
      "\n",
      "Sample 2:\n",
      "Last year in 2014, the earth had the warmest temperature in recorded history. Needless to say, this is due to greenhouse gases, like carbon dioxide. One of the major reasons behind an increase in greenhouse gases is due to the use of cars and motorcycles, which release high amounts of carbon dioxide...\n",
      "\n",
      "Sample 3:\n",
      "Dear state senator, The Electoral College that was established by the founding fathers in the constitution is important to all of us. Every candidate that is running for President in each state has its own group of electors that the political party of the candidate chose. I am however, not in favor ...\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Example AI texts (label=1):\n",
      "================================================================================\n",
      "\n",
      "Sample 6:\n",
      "Magnus Carlsen, born in 1990, is a Norwegian chess grandmaster and the reigning World Chess Champion since 2013. Known for his exceptional strategic insight, versatility, and endgame prowess, Carlsen became a grandmaster at the age of 13, making him one of the youngest in history. His rise to promin...\n",
      "\n",
      "Sample 7:\n",
      "\"Egypt, a land of ancient wonders and modern complexities, stands as a captivating bridge between the past and the present. Located in the northeastern corner of Africa, Egypt's history stretches back thousands of years, making it one of the world's oldest and most storied civilizations.\n",
      "\n",
      "At the hea...\n",
      "\n",
      "Sample 10:\n",
      "\"The Nissan Sunny, a compact sedan that has been part of Nissan's lineup for several decades, stands as a testament to the brand's commitment to affordability, practicality, and reliability. First introduced in the late 1960s, the Sunny quickly gained popularity for its economical performance and st...\n"
     ]
    }
   ],
   "source": [
    "# Display some statistics\n",
    "print(\"Label distribution in test set:\")\n",
    "print(gtest_df['label'].value_counts())\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "# Show a few examples from each class\n",
    "print(\"\\nExample Human texts (label=0):\")\n",
    "print(\"=\"*80)\n",
    "for i, row in gtest_df[gtest_df['label'] == 0].head(3).iterrows():\n",
    "    print(f\"\\nSample {i+1}:\")\n",
    "    print(row['text'][:300] + \"...\" if len(row['text']) > 300 else row['text'])\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"\\nExample AI texts (label=1):\")\n",
    "print(\"=\"*80)\n",
    "for i, row in gtest_df[gtest_df['label'] == 1].head(3).iterrows():\n",
    "    print(f\"\\nSample {i+1}:\")\n",
    "    print(row['text'][:300] + \"...\" if len(row['text']) > 300 else row['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70810b8c",
   "metadata": {},
   "source": [
    "## Step 4: Save to CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0779eaf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Test dataset saved to: gtest_data.csv\n",
      "   Total samples: 120\n",
      "   Columns: ['text', 'label']\n",
      "   File size: 272.14 KB\n",
      "\n",
      "‚úì File saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Save to CSV file\n",
    "output_file = 'gtest_data.csv'\n",
    "gtest_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"‚úÖ Test dataset saved to: {output_file}\")\n",
    "print(f\"   Total samples: {len(gtest_df)}\")\n",
    "print(f\"   Columns: {list(gtest_df.columns)}\")\n",
    "\n",
    "# Verify the saved file\n",
    "import os\n",
    "if os.path.exists(output_file):\n",
    "    file_size = os.path.getsize(output_file) / 1024  # Size in KB\n",
    "    print(f\"   File size: {file_size:.2f} KB\")\n",
    "    print(\"\\n‚úì File saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a26038d",
   "metadata": {},
   "source": [
    "## Step 5: DataFrame Available for Inspection\n",
    "\n",
    "The `gtest_df` DataFrame is now available in memory for you to inspect and play around with. You can use any of the following commands to explore the data:\n",
    "\n",
    "- `gtest_df.head()` - View first few rows\n",
    "- `gtest_df.tail()` - View last few rows\n",
    "- `gtest_df.info()` - Get DataFrame info\n",
    "- `gtest_df.describe()` - Get statistical summary\n",
    "- `gtest_df[gtest_df['label'] == 0]` - Filter human texts\n",
    "- `gtest_df[gtest_df['label'] == 1]` - Filter AI texts\n",
    "- `gtest_df.sample(5)` - Random sample of 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24d652e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame Information:\n",
      "================================================================================\n",
      "<class 'pandas.DataFrame'>\n",
      "RangeIndex: 120 entries, 0 to 119\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype\n",
      "---  ------  --------------  -----\n",
      " 0   text    120 non-null    str  \n",
      " 1   label   120 non-null    int64\n",
      "dtypes: int64(1), str(1)\n",
      "memory usage: 2.0 KB\n",
      "\n",
      "================================================================================\n",
      "\n",
      "DataFrame Summary:\n",
      "================================================================================\n",
      "Total rows: 120\n",
      "Total columns: 2\n",
      "\n",
      "Column names: ['text', 'label']\n",
      "\n",
      "Label counts:\n",
      "{0: 60, 1: 60}\n"
     ]
    }
   ],
   "source": [
    "# Example: Display DataFrame info\n",
    "print(\"DataFrame Information:\")\n",
    "print(\"=\"*80)\n",
    "gtest_df.info()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"\\nDataFrame Summary:\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Total rows: {len(gtest_df)}\")\n",
    "print(f\"Total columns: {len(gtest_df.columns)}\")\n",
    "print(f\"\\nColumn names: {list(gtest_df.columns)}\")\n",
    "print(f\"\\nLabel counts:\")\n",
    "print(gtest_df['label'].value_counts().to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2d0acd81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The United States has been known for life, liberty, and the pursuit of happiness, but that's not all. It's also known for the different freedoms made available and its fair government. The electoral college is a system in which states choose representatives to vote on the president. In the past, there was a big debate on whether or not this process was fair. The electoral college is not fair or trustworthy for many reasons.\n",
      "\n",
      "Imagine that you picked a representative who said they were going to vote for the person you wanted for president. Sadly, they ended up changing their mind. You could end up with a president you don't like or believe in. Voters don't have total control over who their electors vote for. To me, that doesn't sound very fair. If everyone were allowed to vote, the people would be able to ensure that there vote counted towards the person they wanted, and not towards the candidate they were against. Based on multiple polls, a few presidents have won the popular vote, but lost the electoral vote. That means that the candidate which was chosen by the people did not become president. Our founding fathers fought hard for our rights, and it's our right to a fair vote.\n",
      "\n",
      "There are more problems than just an unfair vote. It almost sounds impossible that there could be a tie in a presidential election, but it has almost happened before. In the past, votes have been so close that only a couple thousand have separated the victor from the loser. What would happen if the votes came out to be tied in an election? Who would become president? I'm sure some people could argue that the electoral college could fix this problem, but I don't believe it could. Since there are less people making the decision during the electoral college process, it is even more likely that there could be a tie. If one person were to vote another way, it could be the equivalent of 1,000 people voting the other way. Also, during the electoral college the electors recieve rewards if their candidate wins. The people in that state, or even the whole country supported the electors and helped them make their decision, so they deserve recognition too.\n",
      "\n",
      "The electoral college is not a fair or trustworthy process. Americans have no control over which candidate their electors choose to vote for. Also, there is a better chance for a catastrophic tie. America is all about being fair and giving people the opportunities they deserve. So, let's give Americans the chance for a fair vote.\n",
      "0\n",
      "434\n"
     ]
    }
   ],
   "source": [
    "# Example: Display a random sample\n",
    "print(gtest_df['text'][4])\n",
    "print(gtest_df['label'][4])\n",
    "\n",
    "print(len(gtest_df['text'][4].split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99512af1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 2: Generate AI-Mimicked Human Text using Gemini API\n",
    "\n",
    "This section generates 60 paragraphs of AI text that mimics human writing:\n",
    "- 30 informal/semi-formal tone paragraphs\n",
    "- 30 formal tone paragraphs\n",
    "- Using 6 different topics\n",
    "- Each prompt generates ~1000-1200 words, split into 6 paragraphs of 100-200 words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ed3215",
   "metadata": {},
   "source": [
    "## Step 6: Setup Gemini API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c53760b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Gemini API configured successfully!\n",
      "Model: gemini-2.5-flash\n"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "import time\n",
    "import re\n",
    "\n",
    "# Configure Gemini API\n",
    "# Replace 'YOUR_API_KEY_HERE' with your actual API key\n",
    "API_KEY = 'AIzaSyD8gDwI4qO9A0oigT2nVNG8A-f8_MdwVV8'\n",
    "\n",
    "# Initialize the client\n",
    "client = genai.Client(api_key=API_KEY)\n",
    "\n",
    "# Model to use\n",
    "MODEL_ID = \"gemini-2.5-flash\"\n",
    "\n",
    "print(\"‚úÖ Gemini API configured successfully!\")\n",
    "print(f\"Model: {MODEL_ID}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c35b79d",
   "metadata": {},
   "source": [
    "## Step 7: Define Topics and Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "96e2eadc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Topics and prompt templates defined\n",
      "\n",
      "Topics (6):\n",
      "  1. The role of technology in shaping everyday decision-making\n",
      "  2. How people form and change deeply held beliefs\n",
      "  3. The trade-off between convenience and privacy in modern life\n",
      "  4. What motivates people to pursue long-term goals\n",
      "  5. The impact of social environments on individual behavior\n",
      "  6. How uncertainty influences judgment and choice\n"
     ]
    }
   ],
   "source": [
    "# Define the 6 topics\n",
    "TOPICS = [\n",
    "    \"The role of technology in shaping everyday decision-making\",\n",
    "    \"How people form and change deeply held beliefs\",\n",
    "    \"The trade-off between convenience and privacy in modern life\",\n",
    "    \"What motivates people to pursue long-term goals\",\n",
    "    \"The impact of social environments on individual behavior\",\n",
    "    \"How uncertainty influences judgment and choice\"\n",
    "]\n",
    "\n",
    "# Informal/Semi-formal prompt template\n",
    "INFORMAL_PROMPT_TEMPLATE = \"\"\"Write a 1000‚Äì1200 word paragraph on {topic} as a human might write it in an informal or semi-formal setting.\n",
    "Use natural variation in sentence length and structure.\n",
    "Allow mild repetition or digression.\n",
    "Avoid overly polished or academic phrasing.\n",
    "Do not follow a rigid structure or outline.\n",
    "Write as if expressing thoughts naturally rather than optimizing clarity. Return just the paragraph in clean text no extras.\"\"\"\n",
    "\n",
    "# Formal prompt template\n",
    "FORMAL_PROMPT_TEMPLATE = \"\"\"Write a 1000‚Äì1200 word paragraph on {topic} in a formal but natural human writing style.\n",
    "Use clear sentences and a coherent line of reasoning, but avoid rigid structure or textbook phrasing.\n",
    "Allow mild redundancy or qualification where appropriate.\n",
    "Do not over-optimize clarity or polish.\n",
    "Write as if explaining your thoughts carefully rather than presenting a finished essay. Return just the paragraph in clean text.\"\"\"\n",
    "\n",
    "print(\"‚úÖ Topics and prompt templates defined\")\n",
    "print(f\"\\nTopics ({len(TOPICS)}):\")\n",
    "for i, topic in enumerate(TOPICS, 1):\n",
    "    print(f\"  {i}. {topic}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1934d5e3",
   "metadata": {},
   "source": [
    "## Step 8: Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a16bdde5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Helper functions defined:\n",
      "  - split_into_paragraphs(): Split text into 100-200 word chunks\n",
      "  - generate_text_from_gemini(): Call Gemini API with retry logic\n"
     ]
    }
   ],
   "source": [
    "def split_into_paragraphs(text, min_words=100, max_words=200):\n",
    "    \"\"\"\n",
    "    Split text into paragraphs of 100-200 words at sentence boundaries.\n",
    "    Uses spaCy for sentence segmentation.\n",
    "    \"\"\"\n",
    "    import spacy\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    \n",
    "    doc = nlp(text)\n",
    "    sentences = [sent.text.strip() for sent in doc.sents]\n",
    "    \n",
    "    paragraphs = []\n",
    "    current_paragraph = []\n",
    "    current_word_count = 0\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        sentence_words = len(sentence.split())\n",
    "        \n",
    "        # If adding this sentence would exceed max_words and we already have min_words\n",
    "        if current_word_count + sentence_words > max_words and current_word_count >= min_words:\n",
    "            paragraphs.append(' '.join(current_paragraph))\n",
    "            current_paragraph = [sentence]\n",
    "            current_word_count = sentence_words\n",
    "        else:\n",
    "            current_paragraph.append(sentence)\n",
    "            current_word_count += sentence_words\n",
    "    \n",
    "    # Add remaining paragraph if it meets minimum requirement\n",
    "    if current_word_count >= min_words:\n",
    "        paragraphs.append(' '.join(current_paragraph))\n",
    "    \n",
    "    return paragraphs\n",
    "\n",
    "\n",
    "def generate_text_from_gemini(prompt, max_retries=3):\n",
    "    \"\"\"\n",
    "    Generate text from Gemini API with retry logic.\n",
    "    \"\"\"\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = client.models.generate_content(\n",
    "                model=MODEL_ID,\n",
    "                contents=prompt\n",
    "            )\n",
    "            return response.text\n",
    "        except Exception as e:\n",
    "            print(f\"  ‚ö†Ô∏è  Attempt {attempt + 1} failed: {str(e)}\")\n",
    "            if attempt < max_retries - 1:\n",
    "                wait_time = 2 ** attempt  # Exponential backoff\n",
    "                print(f\"  ‚è≥ Waiting {wait_time} seconds before retry...\")\n",
    "                time.sleep(wait_time)\n",
    "            else:\n",
    "                print(f\"  ‚ùå Failed after {max_retries} attempts\")\n",
    "                return None\n",
    "    return None\n",
    "\n",
    "\n",
    "print(\"‚úÖ Helper functions defined:\")\n",
    "print(\"  - split_into_paragraphs(): Split text into 100-200 word chunks\")\n",
    "print(\"  - generate_text_from_gemini(): Call Gemini API with retry logic\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2b5a12",
   "metadata": {},
   "source": [
    "## Step 9: Generate Informal/Semi-formal Paragraphs (30 total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "baf547cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 30 informal/semi-formal paragraphs...\n",
      "================================================================================\n",
      "\n",
      "üìù Iteration 1/5\n",
      "   Topic: The role of technology in shaping everyday decision-making\n",
      "   ‚è≥ Calling Gemini API...\n",
      "   ‚úÖ Generated 6 paragraphs, selected 6\n",
      "   üìä Total informal paragraphs so far: 6\n",
      "   ‚è≥ Waiting 2 seconds before next API call...\n",
      "\n",
      "üìù Iteration 2/5\n",
      "   Topic: How people form and change deeply held beliefs\n",
      "   ‚è≥ Calling Gemini API...\n",
      "   ‚úÖ Generated 5 paragraphs, selected 5\n",
      "   üìä Total informal paragraphs so far: 11\n",
      "   ‚è≥ Waiting 2 seconds before next API call...\n",
      "\n",
      "üìù Iteration 3/5\n",
      "   Topic: The trade-off between convenience and privacy in modern life\n",
      "   ‚è≥ Calling Gemini API...\n",
      "   ‚úÖ Generated 6 paragraphs, selected 6\n",
      "   üìä Total informal paragraphs so far: 17\n",
      "   ‚è≥ Waiting 2 seconds before next API call...\n",
      "\n",
      "üìù Iteration 4/5\n",
      "   Topic: What motivates people to pursue long-term goals\n",
      "   ‚è≥ Calling Gemini API...\n",
      "   ‚úÖ Generated 6 paragraphs, selected 6\n",
      "   üìä Total informal paragraphs so far: 23\n",
      "   ‚è≥ Waiting 2 seconds before next API call...\n",
      "\n",
      "üìù Iteration 5/5\n",
      "   Topic: The impact of social environments on individual behavior\n",
      "   ‚è≥ Calling Gemini API...\n",
      "   ‚úÖ Generated 5 paragraphs, selected 5\n",
      "   üìä Total informal paragraphs so far: 28\n",
      "\n",
      "================================================================================\n",
      "‚úÖ Informal paragraph generation complete!\n",
      "   Total paragraphs generated: 28\n"
     ]
    }
   ],
   "source": [
    "# Generate 30 informal paragraphs (5 iterations √ó 6 paragraphs each)\n",
    "informal_paragraphs = []\n",
    "informal_full_texts = []  # Store full responses for inspection\n",
    "\n",
    "print(\"Generating 30 informal/semi-formal paragraphs...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# We need 5 iterations to get 30 paragraphs (5 √ó 6 = 30)\n",
    "for iteration in range(5):\n",
    "    topic = TOPICS[iteration % len(TOPICS)]  # Cycle through topics\n",
    "    \n",
    "    print(f\"\\nüìù Iteration {iteration + 1}/5\")\n",
    "    print(f\"   Topic: {topic}\")\n",
    "    \n",
    "    # Create prompt\n",
    "    prompt = INFORMAL_PROMPT_TEMPLATE.format(topic=topic)\n",
    "    \n",
    "    # Generate text\n",
    "    print(\"   ‚è≥ Calling Gemini API...\")\n",
    "    generated_text = generate_text_from_gemini(prompt)\n",
    "    \n",
    "    if generated_text:\n",
    "        # Store full text\n",
    "        informal_full_texts.append({\n",
    "            'iteration': iteration + 1,\n",
    "            'topic': topic,\n",
    "            'formality': 'informal',\n",
    "            'full_text': generated_text,\n",
    "            'word_count': len(generated_text.split())\n",
    "        })\n",
    "        \n",
    "        # Split into paragraphs\n",
    "        paragraphs = split_into_paragraphs(generated_text)\n",
    "        \n",
    "        # Take first 6 paragraphs (or all if less than 6)\n",
    "        selected_paragraphs = paragraphs[:6]\n",
    "        informal_paragraphs.extend(selected_paragraphs)\n",
    "        \n",
    "        print(f\"   ‚úÖ Generated {len(paragraphs)} paragraphs, selected {len(selected_paragraphs)}\")\n",
    "        print(f\"   üìä Total informal paragraphs so far: {len(informal_paragraphs)}\")\n",
    "    else:\n",
    "        print(f\"   ‚ùå Failed to generate text for iteration {iteration + 1}\")\n",
    "    \n",
    "    # Wait between API calls to avoid rate limits\n",
    "    if iteration < 4:  # Don't wait after the last iteration\n",
    "        print(\"   ‚è≥ Waiting 2 seconds before next API call...\")\n",
    "        time.sleep(2)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(f\"‚úÖ Informal paragraph generation complete!\")\n",
    "print(f\"   Total paragraphs generated: {len(informal_paragraphs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3371ca",
   "metadata": {},
   "source": [
    "## Step 10: Generate Formal Paragraphs (30 total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "357ffd67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 30 formal paragraphs...\n",
      "================================================================================\n",
      "\n",
      "üìù Iteration 1/5\n",
      "   Topic: The role of technology in shaping everyday decision-making\n",
      "   ‚è≥ Calling Gemini API...\n",
      "   ‚úÖ Generated 6 paragraphs, selected 6\n",
      "   üìä Total formal paragraphs so far: 6\n",
      "   ‚è≥ Waiting 2 seconds before next API call...\n",
      "\n",
      "üìù Iteration 2/5\n",
      "   Topic: How people form and change deeply held beliefs\n",
      "   ‚è≥ Calling Gemini API...\n",
      "   ‚úÖ Generated 5 paragraphs, selected 5\n",
      "   üìä Total formal paragraphs so far: 11\n",
      "   ‚è≥ Waiting 2 seconds before next API call...\n",
      "\n",
      "üìù Iteration 3/5\n",
      "   Topic: The trade-off between convenience and privacy in modern life\n",
      "   ‚è≥ Calling Gemini API...\n",
      "   ‚úÖ Generated 6 paragraphs, selected 6\n",
      "   üìä Total formal paragraphs so far: 17\n",
      "   ‚è≥ Waiting 2 seconds before next API call...\n",
      "\n",
      "üìù Iteration 4/5\n",
      "   Topic: What motivates people to pursue long-term goals\n",
      "   ‚è≥ Calling Gemini API...\n",
      "   ‚úÖ Generated 3 paragraphs, selected 3\n",
      "   üìä Total formal paragraphs so far: 20\n",
      "   ‚è≥ Waiting 2 seconds before next API call...\n",
      "\n",
      "üìù Iteration 5/5\n",
      "   Topic: The impact of social environments on individual behavior\n",
      "   ‚è≥ Calling Gemini API...\n",
      "   ‚úÖ Generated 6 paragraphs, selected 6\n",
      "   üìä Total formal paragraphs so far: 26\n",
      "\n",
      "================================================================================\n",
      "‚úÖ Formal paragraph generation complete!\n",
      "   Total paragraphs generated: 26\n"
     ]
    }
   ],
   "source": [
    "# Generate 30 formal paragraphs (5 iterations √ó 6 paragraphs each)\n",
    "formal_paragraphs = []\n",
    "formal_full_texts = []  # Store full responses for inspection\n",
    "\n",
    "print(\"Generating 30 formal paragraphs...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# We need 5 iterations to get 30 paragraphs (5 √ó 6 = 30)\n",
    "for iteration in range(5):\n",
    "    topic = TOPICS[iteration % len(TOPICS)]  # Cycle through topics\n",
    "    \n",
    "    print(f\"\\nüìù Iteration {iteration + 1}/5\")\n",
    "    print(f\"   Topic: {topic}\")\n",
    "    \n",
    "    # Create prompt\n",
    "    prompt = FORMAL_PROMPT_TEMPLATE.format(topic=topic)\n",
    "    \n",
    "    # Generate text\n",
    "    print(\"   ‚è≥ Calling Gemini API...\")\n",
    "    generated_text = generate_text_from_gemini(prompt)\n",
    "    \n",
    "    if generated_text:\n",
    "        # Store full text\n",
    "        formal_full_texts.append({\n",
    "            'iteration': iteration + 1,\n",
    "            'topic': topic,\n",
    "            'formality': 'formal',\n",
    "            'full_text': generated_text,\n",
    "            'word_count': len(generated_text.split())\n",
    "        })\n",
    "        \n",
    "        # Split into paragraphs\n",
    "        paragraphs = split_into_paragraphs(generated_text)\n",
    "        \n",
    "        # Take first 6 paragraphs (or all if less than 6)\n",
    "        selected_paragraphs = paragraphs[:6]\n",
    "        formal_paragraphs.extend(selected_paragraphs)\n",
    "        \n",
    "        print(f\"   ‚úÖ Generated {len(paragraphs)} paragraphs, selected {len(selected_paragraphs)}\")\n",
    "        print(f\"   üìä Total formal paragraphs so far: {len(formal_paragraphs)}\")\n",
    "    else:\n",
    "        print(f\"   ‚ùå Failed to generate text for iteration {iteration + 1}\")\n",
    "    \n",
    "    # Wait between API calls to avoid rate limits\n",
    "    if iteration < 4:  # Don't wait after the last iteration\n",
    "        print(\"   ‚è≥ Waiting 2 seconds before next API call...\")\n",
    "        time.sleep(2)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(f\"‚úÖ Formal paragraph generation complete!\")\n",
    "print(f\"   Total paragraphs generated: {len(formal_paragraphs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0b92d3",
   "metadata": {},
   "source": [
    "## Step 11: Combine All Paragraphs and Create DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "59f0a036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total AI-mimicked paragraphs: 54\n",
      "  - Informal: 28\n",
      "  - Formal: 26\n",
      "\n",
      "‚ö†Ô∏è  Only generated 54 paragraphs. Need 6 more.\n",
      "\n",
      "‚úÖ Created AI-mimicked DataFrame:\n",
      "   Shape: (54, 2)\n",
      "   Columns: ['text', 'label']\n",
      "\n",
      "Sample rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It's actually wild, isn't it, when you stop fo...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Remember when you‚Äôd just pick a place you knew...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>On one hand, technology streamlines things; ou...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  It's actually wild, isn't it, when you stop fo...      2\n",
       "1  Remember when you‚Äôd just pick a place you knew...      2\n",
       "2  On one hand, technology streamlines things; ou...      2"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine all AI-mimicked paragraphs\n",
    "all_ai_mimic_paragraphs = informal_paragraphs + formal_paragraphs\n",
    "\n",
    "print(f\"Total AI-mimicked paragraphs: {len(all_ai_mimic_paragraphs)}\")\n",
    "print(f\"  - Informal: {len(informal_paragraphs)}\")\n",
    "print(f\"  - Formal: {len(formal_paragraphs)}\")\n",
    "\n",
    "# If we have more than 60, take the first 60\n",
    "if len(all_ai_mimic_paragraphs) > 60:\n",
    "    print(f\"\\n‚ö†Ô∏è  Generated {len(all_ai_mimic_paragraphs)} paragraphs. Taking first 60.\")\n",
    "    all_ai_mimic_paragraphs = all_ai_mimic_paragraphs[:60]\n",
    "elif len(all_ai_mimic_paragraphs) < 60:\n",
    "    print(f\"\\n‚ö†Ô∏è  Only generated {len(all_ai_mimic_paragraphs)} paragraphs. Need {60 - len(all_ai_mimic_paragraphs)} more.\")\n",
    "\n",
    "# Create DataFrame for AI-mimicked text with label=2\n",
    "ai_mimic_df = pd.DataFrame({\n",
    "    'text': all_ai_mimic_paragraphs,\n",
    "    'label': [2] * len(all_ai_mimic_paragraphs)  # label=2 for AI-mimicked text\n",
    "})\n",
    "\n",
    "print(f\"\\n‚úÖ Created AI-mimicked DataFrame:\")\n",
    "print(f\"   Shape: {ai_mimic_df.shape}\")\n",
    "print(f\"   Columns: {list(ai_mimic_df.columns)}\")\n",
    "print(f\"\\nSample rows:\")\n",
    "ai_mimic_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84442e8b",
   "metadata": {},
   "source": [
    "## Step 12: Merge with Existing Data and Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b1fc741a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current gtest_df:\n",
      "  Shape: (120, 2)\n",
      "  Label distribution:\n",
      "label\n",
      "0    60\n",
      "1    60\n",
      "Name: count, dtype: int64\n",
      "\n",
      "‚úÖ Final combined dataset:\n",
      "  Shape: (174, 2)\n",
      "  Label distribution:\n",
      "label\n",
      "0    60\n",
      "1    60\n",
      "2    54\n",
      "Name: count, dtype: int64\n",
      "\n",
      "  Label key:\n",
      "    0 = Human\n",
      "    1 = AI\n",
      "    2 = AI-mimicked Human\n",
      "\n",
      "‚úÖ Saved to: gtest_data.csv\n",
      "   Total samples: 174\n",
      "\n",
      "‚úÖ gtest_df updated with all 3 classes and available for inspection!\n"
     ]
    }
   ],
   "source": [
    "# Combine with existing gtest_df (which has 60 human + 60 AI samples)\n",
    "print(\"Current gtest_df:\")\n",
    "print(f\"  Shape: {gtest_df.shape}\")\n",
    "print(f\"  Label distribution:\")\n",
    "print(gtest_df['label'].value_counts())\n",
    "\n",
    "# Append AI-mimicked data\n",
    "gtest_df_final = pd.concat([gtest_df, ai_mimic_df], ignore_index=True)\n",
    "\n",
    "# Shuffle the final dataset\n",
    "gtest_df_final = gtest_df_final.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "print(f\"\\n‚úÖ Final combined dataset:\")\n",
    "print(f\"  Shape: {gtest_df_final.shape}\")\n",
    "print(f\"  Label distribution:\")\n",
    "print(gtest_df_final['label'].value_counts().sort_index())\n",
    "print(f\"\\n  Label key:\")\n",
    "print(f\"    0 = Human\")\n",
    "print(f\"    1 = AI\")\n",
    "print(f\"    2 = AI-mimicked Human\")\n",
    "\n",
    "# Save to CSV\n",
    "output_file = 'gtest_data.csv'\n",
    "gtest_df_final.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"\\n‚úÖ Saved to: {output_file}\")\n",
    "print(f\"   Total samples: {len(gtest_df_final)}\")\n",
    "\n",
    "# Update the gtest_df variable to point to the final version\n",
    "gtest_df = gtest_df_final\n",
    "\n",
    "print(f\"\\n‚úÖ gtest_df updated with all 3 classes and available for inspection!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41536c4",
   "metadata": {},
   "source": [
    "## Step 13: Inspect Final Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "02a292fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Dataset Summary\n",
      "================================================================================\n",
      "Total samples: 174\n",
      "\n",
      "Label distribution:\n",
      "  0 (Human          ): 60 samples\n",
      "  1 (AI             ): 60 samples\n",
      "  2 (AI-mimicked    ): 54 samples\n",
      "\n",
      "DataFrame info:\n",
      "<class 'pandas.DataFrame'>\n",
      "RangeIndex: 174 entries, 0 to 173\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype\n",
      "---  ------  --------------  -----\n",
      " 0   text    174 non-null    str  \n",
      " 1   label   174 non-null    int64\n",
      "dtypes: int64(1), str(1)\n",
      "memory usage: 2.8 KB\n",
      "\n",
      "================================================================================\n",
      "Sample from each class:\n",
      "================================================================================\n",
      "\n",
      "Human (label=0):\n",
      "--------------------------------------------------------------------------------\n",
      "When were voting for president were not technically voting for the president in fact we are voting for the slate of electors. The electors can be anyone without a public holding office. Electoral college process is not a good process for presidency. While a president can get the majority of the popular vote on the other hand, he could have the minority of the electoral college votes. That presiden...\n",
      "\n",
      "Word count: 426\n",
      "\n",
      "AI (label=1):\n",
      "--------------------------------------------------------------------------------\n",
      "\"Plastic water bottles, a ubiquitous sight in daily life, represent convenience and accessibility in hydration. However, they also pose significant environmental challenges. These bottles, often made from polyethylene terephthalate (PET), have become a symbol of modern society's reliance on disposable products. While they offer the convenience of portable and safe drinking water, their widespread ...\n",
      "\n",
      "Word count: 306\n",
      "\n",
      "AI-mimicked (label=2):\n",
      "--------------------------------------------------------------------------------\n",
      "We naturally gravitate towards information and interpretations that affirm our existing beliefs, a phenomenon known as confirmation bias, which further solidifies these convictions and creates a cognitive filter through which new information is processed, often unconsciously dismissing or reinterpreting anything that contradicts our established worldview. Our social circles, often comprised of ind...\n",
      "\n",
      "Word count: 177\n",
      "\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>We naturally gravitate towards information and...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>And then you move out of that initial, super-i...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>When were voting for president were not techni...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>And then, as we get older, these foundational ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>It‚Äôs like putting money in a mental bank accou...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>It might be a vision of a future self‚Äîa health...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\"Plastic water bottles, a ubiquitous sight in ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Limiting car use causes pollution, increases c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>It's really something, isn't it, how we come t...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Dear Senator, I know that you have many issues...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  We naturally gravitate towards information and...      2\n",
       "1  And then you move out of that initial, super-i...      2\n",
       "2  When were voting for president were not techni...      0\n",
       "3  And then, as we get older, these foundational ...      2\n",
       "4  It‚Äôs like putting money in a mental bank accou...      2\n",
       "5  It might be a vision of a future self‚Äîa health...      2\n",
       "6  \"Plastic water bottles, a ubiquitous sight in ...      1\n",
       "7  Limiting car use causes pollution, increases c...      1\n",
       "8  It's really something, isn't it, how we come t...      2\n",
       "9  Dear Senator, I know that you have many issues...      0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display summary statistics\n",
    "print(\"Final Dataset Summary\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Total samples: {len(gtest_df)}\")\n",
    "print(f\"\\nLabel distribution:\")\n",
    "for label, count in gtest_df['label'].value_counts().sort_index().items():\n",
    "    label_name = {0: 'Human', 1: 'AI', 2: 'AI-mimicked'}[label]\n",
    "    print(f\"  {label} ({label_name:15s}): {count} samples\")\n",
    "\n",
    "print(f\"\\nDataFrame info:\")\n",
    "gtest_df.info()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Sample from each class:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for label in [0, 1, 2]:\n",
    "    label_name = {0: 'Human', 1: 'AI', 2: 'AI-mimicked'}[label]\n",
    "    sample = gtest_df[gtest_df['label'] == label].iloc[0]\n",
    "    print(f\"\\n{label_name} (label={label}):\")\n",
    "    print(\"-\" * 80)\n",
    "    print(sample['text'][:400] + \"...\" if len(sample['text']) > 400 else sample['text'])\n",
    "    print(f\"\\nWord count: {len(sample['text'].split())}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "gtest_df.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
